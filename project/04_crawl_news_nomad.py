import pandas as pd
import requests
import time
import os
from tqdm import tqdm
from pykrx import stock
import urllib3
import warnings

# === âš™ï¸ ì„¤ì • ===
CLIENT_ID = "La91HyCspMz9MzCOarTd"
CLIENT_SECRET = "xATf_CxCzL"

CANDIDATE_FILE = "data/news_candidates.csv" 
RESULT_FILE = "data/final_dataset_nomad.csv" 

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# === ğŸ“– í‚¤ì›Œë“œ ì‚¬ì „ ===
KEYWORDS = {
    "S": ["ë‹¨ë…", "ì„¸ê³„ ìµœì´ˆ", "ì„¸ê³„ìµœì´ˆ", "êµ­ë‚´ ìµœì´ˆ", "FDA ìŠ¹ì¸", "ì„ìƒ 3ìƒ", "ì¸ìˆ˜", "ê²½ì˜ê¶Œ", "ë¬´ìƒì¦ì"],
    "A": ["ê³„ì•½", "ìˆ˜ì£¼", "ê³µê¸‰", "ì²´ê²°", "MOU", "í˜‘ì•½", "ì‚¬ìƒ ìµœëŒ€", "í‘ì", "ì–´ë‹", "íŠ¹í—ˆ", "ê°œë°œ", "ë‹¨ì¼íŒë§¤", "ê³µê¸‰ê³„ì•½"],
    "B": ["íŠ¹ì§•ì£¼", "ì†ë³´", "ê¸‰ë“±", "ìƒí•œê°€", "ì‹ ê³ ê°€", "íˆ¬ì", "ì§„ì¶œ", "í˜‘ë ¥"],
    "BAD": ["ìœ ìƒì¦ì", "ì¶”ê°€ìƒì¥", "CB", "BW", "í™˜ê¸°", "ê´€ë¦¬", "íš¡ë ¹", "ë°°ì„", "ì†Œì†¡", "ë¶ˆì„±ì‹¤", "ê°ì"]
}

# 1. íŒŒì¼ í™•ì¸
if not os.path.exists(CANDIDATE_FILE):
    print("âŒ 3ë‹¨ê³„ íŒŒì¼(news_candidates.csv)ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# 2. ì´ì–´í•˜ê¸° ì„¤ì • (í•µì‹¬ ìˆ˜ì • íŒŒíŠ¸ ğŸ› ï¸)
processed_keys = set()
if os.path.exists(RESULT_FILE):
    # ì½ì„ ë•Œë¶€í„° ì¢…ëª©ì½”ë“œë¥¼ 'ë¬¸ìì—´'ë¡œ ê°•ì œ ì§€ì • (dtype={'Code': str})
    df_existing = pd.read_csv(RESULT_FILE, dtype={'Code': str})
    
    # 6ìë¦¬ë¡œ í™•ì‹¤í•˜ê²Œ í¬ë§·íŒ… (í˜¹ì‹œ ëª¨ë¥¼ ì˜¤ë¥˜ ë°©ì§€)
    processed_codes = df_existing['Code'].apply(lambda x: f"{str(x).strip():0>6}")
    processed_dates = df_existing['Date'].astype(str).str[:10]
    
    processed_keys = set(processed_codes + "_" + processed_dates)
    print(f"ğŸ”„ ì´ì–´í•˜ê¸°: ê¸°ì¡´ {len(df_existing)}ê±´ ì™„ë£Œë¨. (ì¤‘ë³µ ìŠ¤í‚µ)")

# íƒ€ê²Ÿ íŒŒì¼ ë¡œë“œ ì‹œì—ë„ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜
targets = pd.read_csv(CANDIDATE_FILE, dtype={'Code': str}) 
results = []
batch_count = 0
api_call_count = 0

# 3. ì¢…ëª©ëª… ë§¤í•‘
print("ğŸ“Œ ì¢…ëª©ëª… ë§¤í•‘ ì¤‘...")
ticker_to_name = {}
for code in targets['Code'].unique():
    try:
        str_code = f"{str(code):0>6}" # ë¬¸ìì—´ ë³´ì¥
        ticker_to_name[str_code] = stock.get_market_ticker_name(str_code)
    except: continue

print(f"ğŸš€ ì±… ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (ëŒ€ìƒ: {len(targets)}ê±´)")

# 4. í¬ë¡¤ë§ ë£¨í”„
for idx, row in tqdm(targets.iterrows(), total=len(targets), desc="ì¬ë£Œ ë¶„ì„ ì¤‘"):
    # ì—¬ê¸°ì„œë„ 6ìë¦¬ ë¬¸ìì—´ë¡œ í™•ì‹¤íˆ ë³€í™˜
    code = f"{str(row['Code']).strip():0>6}"
    target_date = str(row['Date'])[:10]
    
    unique_key = f"{code}_{target_date}"
    
    # ì¤‘ë³µ ì²´í¬
    if unique_key in processed_keys: continue
    
    # ì•ˆì „ë§ˆì§„ (í•˜ë£¨ 24,500ê±´)
    if api_call_count >= 24500:
        print("â›” API í•œë„ ì†Œì§„ (ì¹´ìš´í„° ê¸°ì¤€)! ë‚´ì¼ ì´ì–´ì„œ í•˜ì„¸ìš”.")
        break

    try:
        stock_name = ticker_to_name.get(code, "")
        if not stock_name: continue
            
        query = stock_name
        
        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET}
        params = {"query": query, "display": 100, "sort": "date"}
        
        res = requests.get(url, headers=headers, params=params, timeout=5)
        api_call_count += 1
        
        # ğŸš¨ ì¤‘ìš”: ì‹¤ì œ API í•œë„ ì´ˆê³¼(429) ì‹œ ì¦‰ì‹œ ì¢…ë£Œ (í—›ëŒê¸° ë°©ì§€)
        if res.status_code == 429:
            print("â›” ë„¤ì´ë²„ API í•œë„ ì´ˆê³¼ (429 Error)! ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if res.status_code != 200: 
            time.sleep(0.1)
            continue
            
        items = res.json().get('items', [])
        
        best_grade = "None"
        best_keyword = ""
        news_title = ""
        
        for item in items:
            title = item['title'].replace("<b>", "").replace("</b>", "").replace("&quot;", "")
            
            # ì•…ì¬ í•„í„°
            is_bad = False
            for k in KEYWORDS["BAD"]:
                if k in title:
                    is_bad = True
                    best_keyword = k
                    break
            
            if is_bad: 
                best_grade = "BAD"
                news_title = title
                break 

            # í˜¸ì¬ ë“±ê¸‰
            found = False
            for grade in ["S", "A", "B"]:
                for k in KEYWORDS[grade]:
                    if k in title:
                        best_grade = grade
                        best_keyword = k
                        news_title = title
                        found = True
                        break
                if found: break
            
            if found: break
            
        results.append({
            'Code': code, # 6ìë¦¬ ë¬¸ìì—´ë¡œ ì €ì¥
            'Name': stock_name,
            'Date': target_date,
            'Close': row['Close'],
            'Volume': row['Volume'],
            'Grade': best_grade,
            'Keyword': best_keyword,
            'Title': news_title
        })
        
        time.sleep(0.05)
        
        batch_count += 1
        if batch_count % 1000 == 0:
            mode = 'a' if os.path.exists(RESULT_FILE) else 'w'
            header = not os.path.exists(RESULT_FILE)
            pd.DataFrame(results).to_csv(RESULT_FILE, mode=mode, header=header, index=False)
            results = []
            print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ ({batch_count}ê±´)")

    except Exception as e:
        continue

# ë‚¨ì€ ë°ì´í„° ì €ì¥
if results:
    mode = 'a' if os.path.exists(RESULT_FILE) else 'w'
    header = not os.path.exists(RESULT_FILE)
    pd.DataFrame(results).to_csv(RESULT_FILE, mode=mode, header=header, index=False)

print(f"\nğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {RESULT_FILE}")
print(f"ì´ API í˜¸ì¶œ íšŸìˆ˜: {api_call_count}íšŒ")